{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Financial Forecasting with Covariates & Exogenous Variables\n",
    "## A Practical Guide for JPMorgan-Style Analysis\n",
    "\n",
    "This notebook demonstrates how to properly incorporate different types of covariates in financial time series forecasting:\n",
    "- Exogenous variables (macro factors)\n",
    "- Future-known covariates (calendar features)\n",
    "- Lagged covariates (historical values)\n",
    "- Static covariates (unchanging characteristics)\n",
    "\n",
    "We'll build a stock price forecasting model that combines all these effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (15, 6)\n",
    "\n",
    "# Reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate Realistic Financial Dataset\n",
    "\n",
    "We'll create a synthetic dataset that mimics real financial markets with:\n",
    "- Stock prices influenced by market conditions\n",
    "- Macro-economic factors (exogenous)\n",
    "- Calendar effects (future-known)\n",
    "- Company characteristics (static)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_financial_dataset(n_days=1000, start_date='2021-01-01'):\n",
    "    \"\"\"\n",
    "    Generate realistic financial dataset with multiple covariate types\n",
    "    \"\"\"\n",
    "    # Create date range (business days only)\n",
    "    dates = pd.bdate_range(start=start_date, periods=n_days, freq='B')\n",
    "    \n",
    "    df = pd.DataFrame({'date': dates})\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    \n",
    "    # ============================================\n",
    "    # FUTURE-KNOWN COVARIATES (Calendar features)\n",
    "    # ============================================\n",
    "    df['day_of_week'] = df['date'].dt.dayofweek  # 0=Monday, 4=Friday\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['quarter'] = df['date'].dt.quarter\n",
    "    df['day_of_month'] = df['date'].dt.day\n",
    "    df['is_month_end'] = (df['date'].dt.is_month_end).astype(int)\n",
    "    df['is_quarter_end'] = ((df['date'].dt.month % 3 == 0) & df['is_month_end']).astype(int)\n",
    "    \n",
    "    # Earnings dates (scheduled quarterly, known in advance)\n",
    "    df['is_earnings_day'] = ((df['day_of_month'] >= 20) & \n",
    "                             (df['day_of_month'] <= 22) & \n",
    "                             df['is_quarter_end']).astype(int)\n",
    "    \n",
    "    # ============================================\n",
    "    # EXOGENOUS VARIABLES (External macro factors)\n",
    "    # ============================================\n",
    "    \n",
    "    # Interest rates (slow-moving, controlled by Fed)\n",
    "    base_rate = 2.0\n",
    "    rate_changes = np.cumsum(np.random.normal(0, 0.01, n_days))\n",
    "    df['interest_rate'] = np.clip(base_rate + rate_changes, 0.5, 5.0)\n",
    "    \n",
    "    # Market index (S&P 500 proxy - affects all stocks)\n",
    "    market_trend = 0.0003 * np.arange(n_days)  # Slow upward trend\n",
    "    market_volatility = np.random.normal(0, 0.02, n_days)\n",
    "    market_seasonal = 0.05 * np.sin(2 * np.pi * np.arange(n_days) / 252)  # Yearly cycle\n",
    "    df['market_index'] = 100 * np.exp(np.cumsum(market_trend + market_volatility + market_seasonal))\n",
    "    \n",
    "    # VIX (volatility index - fear gauge)\n",
    "    base_vix = 15\n",
    "    vix_shocks = np.random.choice([0, 0, 0, 5, -3], n_days)  # Occasional spikes\n",
    "    df['vix'] = np.clip(base_vix + np.cumsum(np.random.normal(0, 1, n_days)) + vix_shocks, 10, 50)\n",
    "    \n",
    "    # GDP Growth Rate (quarterly data, slow-moving)\n",
    "    gdp_base = 2.5\n",
    "    gdp_quarterly = gdp_base + np.random.normal(0, 0.5, n_days // 63 + 1)\n",
    "    df['gdp_growth'] = np.repeat(gdp_quarterly, 63)[:n_days]\n",
    "    \n",
    "    # Unemployment rate (economic health indicator)\n",
    "    unemployment_base = 5.0\n",
    "    unemployment_trend = -0.00002 * np.arange(n_days)  # Slowly improving\n",
    "    df['unemployment_rate'] = np.clip(\n",
    "        unemployment_base + unemployment_trend + np.cumsum(np.random.normal(0, 0.02, n_days)),\n",
    "        3.5, 8.0\n",
    "    )\n",
    "    \n",
    "    # Oil prices (affects many sectors)\n",
    "    oil_base = 60\n",
    "    oil_volatility = np.random.normal(0, 2, n_days)\n",
    "    df['oil_price'] = np.clip(oil_base + np.cumsum(oil_volatility), 40, 100)\n",
    "    \n",
    "    # ============================================\n",
    "    # TARGET: STOCK PRICE (influenced by above)\n",
    "    # ============================================\n",
    "    \n",
    "    stock_base = 100\n",
    "    \n",
    "    # Company-specific trend\n",
    "    company_trend = 0.0005 * np.arange(n_days)\n",
    "    \n",
    "    # Market correlation (beta effect)\n",
    "    market_effect = 0.7 * (df['market_index'].pct_change().fillna(0))\n",
    "    \n",
    "    # Macro factors influence\n",
    "    rate_effect = -0.3 * df['interest_rate'].pct_change().fillna(0)  # Inverse relationship\n",
    "    vix_effect = -0.2 * df['vix'].pct_change().fillna(0)  # High VIX = risk off\n",
    "    \n",
    "    # Calendar effects\n",
    "    monday_effect = -0.002 * (df['day_of_week'] == 0)  # Monday slightly negative\n",
    "    friday_effect = 0.001 * (df['day_of_week'] == 4)   # Friday slightly positive\n",
    "    earnings_effect = 0.03 * df['is_earnings_day']      # Earnings day volatility\n",
    "    month_end_effect = 0.005 * df['is_month_end']       # Month-end rebalancing\n",
    "    \n",
    "    # Company-specific volatility\n",
    "    idiosyncratic = np.random.normal(0, 0.015, n_days)\n",
    "    \n",
    "    # Combine all effects\n",
    "    returns = (company_trend + market_effect + rate_effect + vix_effect +\n",
    "               monday_effect + friday_effect + earnings_effect + \n",
    "               month_end_effect + idiosyncratic)\n",
    "    \n",
    "    df['stock_price'] = stock_base * np.exp(np.cumsum(returns))\n",
    "    \n",
    "    # ============================================\n",
    "    # LAGGED COVARIATES (Historical values)\n",
    "    # ============================================\n",
    "    \n",
    "    # Trading volume (influenced by price movements and VIX)\n",
    "    base_volume = 1000000\n",
    "    volume_from_volatility = base_volume * (1 + 0.02 * df['vix'])\n",
    "    volume_noise = np.random.normal(0, 0.1 * base_volume, n_days)\n",
    "    df['volume'] = np.abs(volume_from_volatility + volume_noise)\n",
    "    \n",
    "    # Price momentum indicators\n",
    "    df['price_return_1d'] = df['stock_price'].pct_change(1).fillna(0)\n",
    "    df['price_return_5d'] = df['stock_price'].pct_change(5).fillna(0)\n",
    "    df['price_return_20d'] = df['stock_price'].pct_change(20).fillna(0)\n",
    "    \n",
    "    # Moving averages (technical indicators)\n",
    "    df['sma_5'] = df['stock_price'].rolling(5).mean().fillna(method='bfill')\n",
    "    df['sma_20'] = df['stock_price'].rolling(20).mean().fillna(method='bfill')\n",
    "    df['sma_50'] = df['stock_price'].rolling(50).mean().fillna(method='bfill')\n",
    "    \n",
    "    # Volatility (20-day rolling std)\n",
    "    df['realized_volatility'] = df['price_return_1d'].rolling(20).std().fillna(method='bfill')\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Generate dataset\n",
    "df = generate_financial_dataset(n_days=1000)\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head(10))\n",
    "print(\"\\nDataset info:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize the Data and Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot stock price and key covariates\n",
    "fig, axes = plt.subplots(4, 1, figsize=(15, 12))\n",
    "\n",
    "# Stock price\n",
    "axes[0].plot(df['date'], df['stock_price'], label='Stock Price', color='blue', linewidth=2)\n",
    "axes[0].set_title('Target: Stock Price', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Price ($)')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Exogenous variables\n",
    "ax1 = axes[1]\n",
    "ax2 = ax1.twinx()\n",
    "ax1.plot(df['date'], df['market_index'], label='Market Index', color='green', alpha=0.7)\n",
    "ax2.plot(df['date'], df['vix'], label='VIX', color='red', alpha=0.7)\n",
    "ax1.set_ylabel('Market Index', color='green')\n",
    "ax2.set_ylabel('VIX', color='red')\n",
    "ax1.set_title('Exogenous Variables: Market Index & VIX', fontsize=12, fontweight='bold')\n",
    "ax1.legend(loc='upper left')\n",
    "ax2.legend(loc='upper right')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# More exogenous variables\n",
    "ax3 = axes[2]\n",
    "ax4 = ax3.twinx()\n",
    "ax3.plot(df['date'], df['interest_rate'], label='Interest Rate', color='purple', alpha=0.7)\n",
    "ax4.plot(df['date'], df['unemployment_rate'], label='Unemployment', color='orange', alpha=0.7)\n",
    "ax3.set_ylabel('Interest Rate (%)', color='purple')\n",
    "ax4.set_ylabel('Unemployment (%)', color='orange')\n",
    "ax3.set_title('Exogenous Variables: Interest Rate & Unemployment', fontsize=12, fontweight='bold')\n",
    "ax3.legend(loc='upper left')\n",
    "ax4.legend(loc='upper right')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Volume (lagged covariate)\n",
    "axes[3].bar(df['date'], df['volume'], label='Trading Volume', color='gray', alpha=0.6, width=1)\n",
    "axes[3].set_title('Lagged Covariate: Trading Volume', fontsize=12, fontweight='bold')\n",
    "axes[3].set_ylabel('Volume')\n",
    "axes[3].set_xlabel('Date')\n",
    "axes[3].legend()\n",
    "axes[3].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis\n",
    "correlation_vars = ['stock_price', 'market_index', 'vix', 'interest_rate', \n",
    "                    'unemployment_rate', 'oil_price', 'volume']\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(df[correlation_vars].corr(), annot=True, cmap='coolwarm', center=0, \n",
    "            fmt='.2f', square=True, linewidths=1)\n",
    "plt.title('Correlation Matrix: Target vs Covariates', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Observations:\")\n",
    "print(\"- Stock price is positively correlated with market index\")\n",
    "print(\"- Negative correlation with VIX (fear index)\")\n",
    "print(\"- Interest rates show inverse relationship\")\n",
    "print(\"- Volume increases with volatility (VIX)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define Covariate Categories\n",
    "\n",
    "Critical step: Properly categorize variables for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define covariate categories\n",
    "covariate_config = {\n",
    "    # What we're trying to predict\n",
    "    'target': 'stock_price',\n",
    "    \n",
    "    # FUTURE-KNOWN: We know these values for future dates\n",
    "    'future_known': [\n",
    "        'day_of_week',\n",
    "        'month', \n",
    "        'quarter',\n",
    "        'day_of_month',\n",
    "        'is_month_end',\n",
    "        'is_quarter_end',\n",
    "        'is_earnings_day'\n",
    "    ],\n",
    "    \n",
    "    # EXOGENOUS: External factors (we can observe but not predict)\n",
    "    # In practice, you'd need separate models to forecast these\n",
    "    # or use external forecasts (e.g., Fed interest rate projections)\n",
    "    'exogenous': [\n",
    "        'market_index',\n",
    "        'vix',\n",
    "        'interest_rate',\n",
    "        'gdp_growth',\n",
    "        'unemployment_rate',\n",
    "        'oil_price'\n",
    "    ],\n",
    "    \n",
    "    # LAGGED: Historical values and derived features\n",
    "    # Can only use past values, not future\n",
    "    'lagged': [\n",
    "        'volume',\n",
    "        'price_return_1d',\n",
    "        'price_return_5d', \n",
    "        'price_return_20d',\n",
    "        'sma_5',\n",
    "        'sma_20',\n",
    "        'sma_50',\n",
    "        'realized_volatility'\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"Covariate Configuration:\")\n",
    "print(\"=\" * 50)\n",
    "for category, variables in covariate_config.items():\n",
    "    if category != 'target':\n",
    "        print(f\"\\n{category.upper()} ({len(variables)} variables):\")\n",
    "        for var in variables:\n",
    "            print(f\"  - {var}\")\n",
    "\n",
    "total_features = (len(covariate_config['future_known']) + \n",
    "                 len(covariate_config['exogenous']) + \n",
    "                 len(covariate_config['lagged']))\n",
    "print(f\"\\nTotal input features: {total_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Dataset with Proper Covariate Handling\n",
    "\n",
    "Key insight: Different covariates can be used differently during training vs. prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinancialTimeSeriesDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset that properly handles different covariate types\n",
    "    \n",
    "    During training:\n",
    "    - Use all covariates (we have historical data)\n",
    "    \n",
    "    During prediction:\n",
    "    - Future-known: Can use actual future values\n",
    "    - Exogenous: Need forecasts or scenarios\n",
    "    - Lagged: Only use historical values\n",
    "    \"\"\"\n",
    "    def __init__(self, df, config, window_size=60, forecast_horizon=5, \n",
    "                 mode='train', scaler=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            df: DataFrame with all data\n",
    "            config: Covariate configuration dictionary\n",
    "            window_size: Number of past days to look at\n",
    "            forecast_horizon: Number of days to predict ahead\n",
    "            mode: 'train' or 'predict'\n",
    "            scaler: Fitted StandardScaler (provide for val/test sets)\n",
    "        \"\"\"\n",
    "        self.df = df.copy()\n",
    "        self.config = config\n",
    "        self.window_size = window_size\n",
    "        self.forecast_horizon = forecast_horizon\n",
    "        self.mode = mode\n",
    "        \n",
    "        # Prepare feature columns\n",
    "        self.target_col = config['target']\n",
    "        self.feature_cols = (config['future_known'] + \n",
    "                            config['exogenous'] + \n",
    "                            config['lagged'])\n",
    "        \n",
    "        # Normalize features\n",
    "        if scaler is None:\n",
    "            self.scaler = StandardScaler()\n",
    "            self.df[self.feature_cols] = self.scaler.fit_transform(\n",
    "                self.df[self.feature_cols]\n",
    "            )\n",
    "        else:\n",
    "            self.scaler = scaler\n",
    "            self.df[self.feature_cols] = self.scaler.transform(\n",
    "                self.df[self.feature_cols]\n",
    "            )\n",
    "        \n",
    "        # Normalize target separately (for easy inverse transform)\n",
    "        self.target_scaler = StandardScaler()\n",
    "        self.df[self.target_col] = self.target_scaler.fit_transform(\n",
    "            self.df[[self.target_col]]\n",
    "        )\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df) - self.window_size - self.forecast_horizon + 1\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Input window: past observations\n",
    "        start_idx = idx\n",
    "        end_idx = idx + self.window_size\n",
    "        \n",
    "        # Extract features for the window\n",
    "        X = self.df[self.feature_cols].iloc[start_idx:end_idx].values\n",
    "        \n",
    "        # Extract target for future period\n",
    "        target_start = end_idx\n",
    "        target_end = end_idx + self.forecast_horizon\n",
    "        y = self.df[self.target_col].iloc[target_start:target_end].values\n",
    "        \n",
    "        # For prediction, also return future-known covariates\n",
    "        # (we know calendar features for the prediction period)\n",
    "        future_known_idx = [self.feature_cols.index(col) \n",
    "                           for col in self.config['future_known']]\n",
    "        future_covariates = self.df[self.config['future_known']].iloc[\n",
    "            target_start:target_end\n",
    "        ].values\n",
    "        \n",
    "        return (\n",
    "            torch.FloatTensor(X),                    # Historical features\n",
    "            torch.FloatTensor(future_covariates),    # Future-known covariates\n",
    "            torch.FloatTensor(y)                     # Target\n",
    "        )\n",
    "\n",
    "# Split data (70/15/15)\n",
    "train_size = int(0.7 * len(df))\n",
    "val_size = int(0.15 * len(df))\n",
    "\n",
    "train_df = df.iloc[:train_size].reset_index(drop=True)\n",
    "val_df = df.iloc[train_size:train_size + val_size].reset_index(drop=True)\n",
    "test_df = df.iloc[train_size + val_size:].reset_index(drop=True)\n",
    "\n",
    "print(f\"Train set: {len(train_df)} days\")\n",
    "print(f\"Validation set: {len(val_df)} days\")\n",
    "print(f\"Test set: {len(test_df)} days\")\n",
    "\n",
    "# Create datasets\n",
    "window_size = 60  # 60 trading days \u2248 3 months\n",
    "forecast_horizon = 5  # Predict next 5 days (1 week)\n",
    "\n",
    "train_dataset = FinancialTimeSeriesDataset(\n",
    "    train_df, covariate_config, window_size, forecast_horizon\n",
    ")\n",
    "\n",
    "val_dataset = FinancialTimeSeriesDataset(\n",
    "    val_df, covariate_config, window_size, forecast_horizon,\n",
    "    scaler=train_dataset.scaler\n",
    ")\n",
    "\n",
    "test_dataset = FinancialTimeSeriesDataset(\n",
    "    test_df, covariate_config, window_size, forecast_horizon,\n",
    "    scaler=train_dataset.scaler\n",
    ")\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Check shapes\n",
    "X_sample, future_cov_sample, y_sample = train_dataset[0]\n",
    "print(f\"\\nSample shapes:\")\n",
    "print(f\"Historical features (X): {X_sample.shape} (window_size, n_features)\")\n",
    "print(f\"Future-known covariates: {future_cov_sample.shape} (forecast_horizon, n_future_known)\")\n",
    "print(f\"Target (y): {y_sample.shape} (forecast_horizon,)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Architecture with Covariate Integration\n",
    "\n",
    "This model architecture properly handles different covariate types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CovariateAwareLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    LSTM that properly integrates different types of covariates\n",
    "    \n",
    "    Architecture:\n",
    "    1. Encode historical sequence (all past covariates)\n",
    "    2. Integrate future-known covariates for prediction period\n",
    "    3. Generate multi-step forecast\n",
    "    \"\"\"\n",
    "    def __init__(self, n_features, n_future_known, hidden_size=128, \n",
    "                 num_layers=2, forecast_horizon=5, dropout=0.2):\n",
    "        super(CovariateAwareLSTM, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.forecast_horizon = forecast_horizon\n",
    "        \n",
    "        # Encoder: Process historical sequence\n",
    "        self.encoder_lstm = nn.LSTM(\n",
    "            input_size=n_features,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout if num_layers > 1 else 0,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Future covariate processor\n",
    "        self.future_cov_processor = nn.Sequential(\n",
    "            nn.Linear(n_future_known, hidden_size // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "        # Decoder: Generate forecasts\n",
    "        # Combines LSTM encoding + future covariates\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_size + hidden_size // 2, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_size, hidden_size // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_size // 2, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x_historical, x_future_known):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x_historical: (batch, window_size, n_features) - all past covariates\n",
    "            x_future_known: (batch, forecast_horizon, n_future_known) - calendar features\n",
    "        \n",
    "        Returns:\n",
    "            predictions: (batch, forecast_horizon) - predicted values\n",
    "        \"\"\"\n",
    "        batch_size = x_historical.size(0)\n",
    "        \n",
    "        # Encode historical sequence\n",
    "        lstm_out, (hidden, cell) = self.encoder_lstm(x_historical)\n",
    "        \n",
    "        # Use last hidden state as context\n",
    "        context = lstm_out[:, -1, :]  # (batch, hidden_size)\n",
    "        \n",
    "        # Generate predictions for each future time step\n",
    "        predictions = []\n",
    "        \n",
    "        for t in range(self.forecast_horizon):\n",
    "            # Get future-known covariates for time t\n",
    "            future_t = x_future_known[:, t, :]  # (batch, n_future_known)\n",
    "            \n",
    "            # Process future covariates\n",
    "            future_encoded = self.future_cov_processor(future_t)\n",
    "            \n",
    "            # Combine context + future covariates\n",
    "            combined = torch.cat([context, future_encoded], dim=1)\n",
    "            \n",
    "            # Predict\n",
    "            pred_t = self.decoder(combined)  # (batch, 1)\n",
    "            predictions.append(pred_t)\n",
    "        \n",
    "        # Stack predictions\n",
    "        predictions = torch.cat(predictions, dim=1)  # (batch, forecast_horizon)\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "# Instantiate model\n",
    "n_features = len(covariate_config['future_known']) + \\\n",
    "             len(covariate_config['exogenous']) + \\\n",
    "             len(covariate_config['lagged'])\n",
    "n_future_known = len(covariate_config['future_known'])\n",
    "\n",
    "model = CovariateAwareLSTM(\n",
    "    n_features=n_features,\n",
    "    n_future_known=n_future_known,\n",
    "    hidden_size=128,\n",
    "    num_layers=2,\n",
    "    forecast_horizon=forecast_horizon,\n",
    "    dropout=0.2\n",
    ").to(device)\n",
    "\n",
    "print(model)\n",
    "print(f\"\\nTotal parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"\\nInput features breakdown:\")\n",
    "print(f\"  - Future-known: {n_future_known}\")\n",
    "print(f\"  - Exogenous: {len(covariate_config['exogenous'])}\")\n",
    "print(f\"  - Lagged: {len(covariate_config['lagged'])}\")\n",
    "print(f\"  - Total: {n_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for x_hist, x_future, y in loader:\n",
    "        x_hist = x_hist.to(device)\n",
    "        x_future = x_future.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(x_hist, x_future)\n",
    "        loss = criterion(predictions, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x_hist, x_future, y in loader:\n",
    "            x_hist = x_hist.to(device)\n",
    "            x_future = x_future.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            predictions = model(x_hist, x_future)\n",
    "            loss = criterion(predictions, y)\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(loader)\n",
    "\n",
    "# Training configuration\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=5, verbose=True\n",
    ")\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 50\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "print(\"Training Covariate-Aware LSTM...\\n\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss = validate(model, val_loader, criterion, device)\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), '/home/claude/best_covariate_model.pth')\n",
    "    \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"  Train Loss: {train_loss:.6f}\")\n",
    "        print(f\"  Val Loss: {val_loss:.6f}\")\n",
    "        print(f\"  Best Val Loss: {best_val_loss:.6f}\")\n",
    "        print()\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(train_losses, label='Train Loss', alpha=0.7, linewidth=2)\n",
    "plt.plot(val_losses, label='Validation Loss', alpha=0.7, linewidth=2)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Loss (MSE)', fontsize=12)\n",
    "plt.title('Training History - Covariate-Aware LSTM', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nTraining complete!\")\n",
    "print(f\"Best validation loss: {best_val_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model and evaluate\n",
    "model.load_state_dict(torch.load('/home/claude/best_covariate_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Make predictions on test set\n",
    "all_predictions = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x_hist, x_future, y in test_loader:\n",
    "        x_hist = x_hist.to(device)\n",
    "        x_future = x_future.to(device)\n",
    "        \n",
    "        predictions = model(x_hist, x_future)\n",
    "        \n",
    "        all_predictions.append(predictions.cpu().numpy())\n",
    "        all_targets.append(y.numpy())\n",
    "\n",
    "predictions = np.concatenate(all_predictions, axis=0)\n",
    "targets = np.concatenate(all_targets, axis=0)\n",
    "\n",
    "# Inverse transform to get actual prices\n",
    "predictions_actual = test_dataset.target_scaler.inverse_transform(\n",
    "    predictions.reshape(-1, 1)\n",
    ").reshape(predictions.shape)\n",
    "\n",
    "targets_actual = test_dataset.target_scaler.inverse_transform(\n",
    "    targets.reshape(-1, 1)\n",
    ").reshape(targets.shape)\n",
    "\n",
    "# Calculate metrics\n",
    "mse = np.mean((predictions_actual - targets_actual) ** 2)\n",
    "mae = np.mean(np.abs(predictions_actual - targets_actual))\n",
    "rmse = np.sqrt(mse)\n",
    "mape = np.mean(np.abs((targets_actual - predictions_actual) / targets_actual)) * 100\n",
    "\n",
    "print(\"Test Set Performance:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"MSE:  {mse:.4f}\")\n",
    "print(f\"MAE:  {mae:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MAPE: {mape:.2f}%\")\n",
    "\n",
    "# Calculate directional accuracy\n",
    "actual_direction = np.sign(targets_actual[:, 1:] - targets_actual[:, :-1])\n",
    "pred_direction = np.sign(predictions_actual[:, 1:] - predictions_actual[:, :-1])\n",
    "directional_accuracy = np.mean(actual_direction == pred_direction) * 100\n",
    "print(f\"\\nDirectional Accuracy: {directional_accuracy:.2f}%\")\n",
    "\n",
    "# Visualize predictions\n",
    "n_examples = 6\n",
    "fig, axes = plt.subplots(n_examples, 1, figsize=(15, 12))\n",
    "\n",
    "for i in range(n_examples):\n",
    "    idx = i * (len(predictions_actual) // n_examples)\n",
    "    time_steps = np.arange(forecast_horizon)\n",
    "    \n",
    "    axes[i].plot(time_steps, targets_actual[idx], \n",
    "                marker='o', label='Actual', linewidth=2, markersize=8)\n",
    "    axes[i].plot(time_steps, predictions_actual[idx], \n",
    "                marker='s', label='Predicted', linewidth=2, markersize=8)\n",
    "    axes[i].fill_between(time_steps, targets_actual[idx], \n",
    "                         predictions_actual[idx], alpha=0.2)\n",
    "    \n",
    "    axes[i].set_ylabel('Price ($)', fontsize=10)\n",
    "    axes[i].set_title(f'Forecast Example {i+1}', fontsize=11, fontweight='bold')\n",
    "    axes[i].legend()\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "axes[-1].set_xlabel('Days Ahead', fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Key Takeaways\n",
    "\n",
    "### What We Learned:\n",
    "\n",
    "1. **Covariate Categories**:\n",
    "   - Future-known (calendar features) \u2192 Can use for predictions\n",
    "   - Exogenous (macro factors) \u2192 Need forecasts or scenarios\n",
    "   - Lagged (historical values) \u2192 Only past available\n",
    "\n",
    "2. **Model Architecture**:\n",
    "   - Separate processing for different covariate types\n",
    "   - Future-known information integrated at prediction time\n",
    "   - Encoder-decoder structure for multi-step forecasting\n",
    "\n",
    "3. **JPMorgan Applications**:\n",
    "   - Trading: Market data as exogenous, calendar as future-known\n",
    "   - Risk: Scenario testing with macro variables\n",
    "   - Credit: Economic indicators as exogenous, payment dates as future-known\n",
    "\n",
    "### Next Steps:\n",
    "- Try with real data (Yahoo Finance, FRED API)\n",
    "- Add attention mechanisms\n",
    "- Implement probabilistic forecasting\n",
    "- Build ensemble models\n",
    "- Add transaction cost modeling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}